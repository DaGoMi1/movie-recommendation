import numpy as np
import pandas as pd
import pickle
import os

def min_max_scale(logits):
    low = logits.min(axis=1, keepdims=True)
    high = logits.max(axis=1, keepdims=True)
    return (logits - low) / (high - low + 1e-9)

def ensemble(w_rvae=0.245, w_m2vae = 0.105, w_bert=0.1125, w_gsas=0.3375, w_ease=0.2):
    print("ðŸš€ Start Ensemble ...")
    print(f"Weights -> RecVAE: {w_rvae}, M2VAE: {w_m2vae}, BERT4Rec: {w_bert}, gSASRec: {w_gsas}, EASE: {w_ease}")
    
    # ê²½ë¡œ ì„¤ì •
    data_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../data"))
    ensemble_dir = os.path.join(data_root, "../logits")
    
    # ë¡œë“œ
    print(f"ðŸ“‚ Loading logits...")
    recvae_logits = np.load(os.path.join(ensemble_dir, "RecVAE_Logits.npy"))
    m2vae_logits = np.load(os.path.join(ensemble_dir, "M2VAE_Logits.npy"))
    ease_logits = np.load(os.path.join(ensemble_dir, "EASE_Logits.npy"))
    bert_logits = np.load(os.path.join(ensemble_dir, "BERT4Rec_Logits.npy"))
    gsas_logits = np.load(os.path.join(ensemble_dir, "gSASRec_Logits.npy"))
    
    # ë§¤í•‘ íŒŒì¼ ë¡œë“œ
    with open(os.path.join(ensemble_dir, "RecVAE_mapping.pkl"), 'rb') as f:
        m_static = pickle.load(f) # ê¸°ì¤€
    with open(os.path.join(ensemble_dir, "BERT4Rec_mapping.pkl"), 'rb') as f:
        m_bert = pickle.load(f)   # BERT ì „ìš©
    with open(os.path.join(ensemble_dir, "gSASRec_mapping.pkl"), 'rb') as f:
        m_gsas = pickle.load(f)   # gSASRec ì „ìš©

    # ìœ ì € ìž¬ë°°ì¹˜ (Row)
    sample_sub_path = os.path.join(data_root, 'eval/sample_submission.csv')
    sample_df = pd.read_csv(sample_sub_path)
    seq_user_order = sample_df['user'].unique()
    
    s_u2idx = m_static['user2idx']
    u_target_idx = [] # ì˜®ê²¨ê°ˆ ìœ„ì¹˜ (RecVAE ìˆœì„œ)
    u_source_row = [] # ê°€ì ¸ì˜¬ ìœ„ì¹˜ (Sequential ëª¨ë¸ npy í–‰)
    
    for r, u_id in enumerate(seq_user_order):
        if u_id in s_u2idx:
            u_target_idx.append(s_u2idx[u_id])
            u_source_row.append(r)

    # ì•„ì´í…œ ìž¬ë°°ì¹˜ (Column)
    s_i2idx = m_static['item2idx']
    b_i2idx = m_bert['item2idx']
    g_i2idx = m_gsas['item2idx']
    
    # BERT4Rec Reorder Index
    b_reorder = []
    # gSASRec Reorder Index
    g_reorder = []
    
    # RecVAE item order ìˆœíšŒ
    for iid, _ in sorted(s_i2idx.items(), key=lambda x: x[1]):
        # BERT Alignment
        if iid in b_i2idx:
            b_col = b_i2idx[iid] - 1
            b_reorder.append(b_col)
        else:
            print(f"Warning: Item {iid} not found in BERT mapping.")
            b_reorder.append(0)
            
        # gSASRec Alignment
        if iid in g_i2idx:
            g_col = g_i2idx[iid] - 1
            g_reorder.append(g_col)
        else:
            print(f"Warning: Item {iid} not found in gSASRec mapping.")
            g_reorder.append(0)

    # ìž¬ì •ë ¬ ì‹¤í–‰
    print("ðŸ”„ Re-aligning Sequence Logits...")
    
    # BERT
    bert_fixed = np.zeros_like(recvae_logits)
    bert_fixed[u_target_idx] = bert_logits[u_source_row][:, b_reorder]
    
    # gSASRec
    gsas_fixed = np.zeros_like(recvae_logits)
    gsas_fixed[u_target_idx] = gsas_logits[u_source_row][:, g_reorder]

    # í•©ì‚°
    print("âš–ï¸ Normalizing and Summing...")
    norm_rvae = min_max_scale(recvae_logits)
    norm_m2vae = min_max_scale(m2vae_logits)
    norm_bert = min_max_scale(bert_fixed)
    norm_gsas = min_max_scale(gsas_fixed)
    norm_ease = min_max_scale(ease_logits)

    combined = (w_rvae * norm_rvae) + (w_m2vae * norm_m2vae) + (w_bert * norm_bert) + (w_gsas * norm_gsas) + (w_ease * norm_ease)

    # ì§„ë‹¨ ë¡œê·¸
    print("-" * 35)
    print(f"User 0 - RecVAE Top 10: {np.argsort(-norm_rvae[0])[:10]}")
    print(f"User 0 - M2VAE Top 10: {np.argsort(-norm_m2vae[0])[:10]}")
    print(f"User 0 - BERT Top 10: {np.argsort(-norm_bert[0])[:10]}")
    print(f"User 0 - gSAS Top 10: {np.argsort(-norm_gsas[0])[:10]}")
    print(f"User 0 - EASE Top 10: {np.argsort(-norm_ease[0])[:10]}")
    print("-" * 35)

    # ë§ˆìŠ¤í‚¹ ë° ì €ìž¥
    train_rating_path = os.path.join(data_root, 'train/train_ratings.csv')
    train_df = pd.read_csv(train_rating_path)
    for u_id, i_id in zip(train_df['user'], train_df['item']):
        if u_id in s_u2idx and i_id in s_i2idx:
            combined[s_u2idx[u_id], s_i2idx[i_id]] = -1e9

    idx2item = m_static['idx2item']
    idx2user = {v: k for k, v in s_u2idx.items()}
    top_indices = np.argsort(-combined, axis=1)[:, :10]
    
    print("\n" + "="*40)
    print("ðŸ‘€ Example: Top 10 Recommendation & Scores for User 0")
    print("="*40)
    # í™•ì¸í•˜ê³  ì‹¶ì€ ìœ ì €ì˜ ì¸ë±ìŠ¤ (ì˜ˆ: 0ë²ˆ ìœ ì €)
    sample_uidx = 0
    
    u_real = idx2user[sample_uidx]
    print(f"User ID: {u_real}")
    
    for rank, i_idx in enumerate(top_indices[sample_uidx], 1):
        item_id = idx2item[i_idx]
        score = combined[sample_uidx, i_idx] # ìµœì¢… ì•™ìƒë¸” ì ìˆ˜
        
        # ê° ëª¨ë¸ë³„ Normalized Logit ê°’ ì¶”ì¶œ
        val_rvae = norm_rvae[sample_uidx, i_idx]
        val_m2vae = norm_m2vae[sample_uidx, i_idx]
        val_bert = norm_bert[sample_uidx, i_idx]
        val_gsas = norm_gsas[sample_uidx, i_idx]
        val_ease = norm_ease[sample_uidx, i_idx]
        
        print(f"Rank {rank:2d} | Item: {item_id} | Final: {score:.6f}")
        print(f"       -> RecVAE: {val_rvae:.4f} | M2VAE: {val_m2vae:.4f} | BERT: {val_bert:.4f} | gSAS: {val_gsas:.4f} | EASE: {val_ease:.4f}")
    
    print("="*40 + "\n")
    
    final_preds = []
    for user_idx, item_indices in enumerate(top_indices):
        u_real = idx2user[user_idx]
        for i_idx in item_indices:
            final_preds.append([u_real, idx2item[i_idx]])
    
    # ì €ìž¥ ê²½ë¡œ ì„¤ì •
    submit_dir = os.path.join(ensemble_dir, "submit")
    if not os.path.exists(submit_dir):
        os.makedirs(submit_dir)
        
    output_filename = f'model_ensemble_(RecVAE({w_rvae})_M2VAE({w_m2vae})_BERT({w_bert})_gSAS({w_gsas})_EASE({w_ease})).csv'
    output_path = os.path.join(submit_dir, output_filename)
    
    pd.DataFrame(final_preds, columns=['user', 'item']).to_csv(output_path, index=False)
    print(f"âœ… Done! File saved as {output_path}")

if __name__ == "__main__":
    ensemble(w_rvae=0.2, w_m2vae=0.2, w_bert=0.2, w_gsas=0.2, w_ease=0.2)